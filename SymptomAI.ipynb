{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6629789,"sourceType":"datasetVersion","datasetId":3827163}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishaanshh7/symptomai?scriptVersionId=184420384\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# Importing libraries \nimport numpy as np \nimport pandas as pd \nfrom scipy.stats import mode \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.model_selection import train_test_split, cross_val_score \nfrom sklearn.svm import SVC \nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(action='ignore', category=UserWarning, module='sklearn')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-19T11:17:49.145717Z","iopub.execute_input":"2024-06-19T11:17:49.146601Z","iopub.status.idle":"2024-06-19T11:17:49.158738Z","shell.execute_reply.started":"2024-06-19T11:17:49.146561Z","shell.execute_reply":"2024-06-19T11:17:49.157581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reading the train.csv by removing the  \n# last column since it's an empty column \nDATA_PATH = \"/kaggle/input/disesase-dataset/d_training.csv\"\ndata = pd.read_csv(DATA_PATH).dropna(axis = 1) ","metadata":{"execution":{"iopub.status.busy":"2024-06-19T10:54:36.86459Z","iopub.execute_input":"2024-06-19T10:54:36.865384Z","iopub.status.idle":"2024-06-19T10:54:36.929217Z","shell.execute_reply.started":"2024-06-19T10:54:36.86535Z","shell.execute_reply":"2024-06-19T10:54:36.928173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T10:52:55.517598Z","iopub.execute_input":"2024-06-19T10:52:55.518564Z","iopub.status.idle":"2024-06-19T10:52:55.540133Z","shell.execute_reply.started":"2024-06-19T10:52:55.518526Z","shell.execute_reply":"2024-06-19T10:52:55.539106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Firstly we will be loading the dataset from the folders using the pandas library. While reading the dataset we will be dropping the null column. This dataset is a clean dataset with no null values and all the features consist of 0’s and 1s. Whenever we are solving a classification task it is necessary to check whether our target column is balanced or not. We will be using a bar plot, to check whether the dataset is balanced or not.  ","metadata":{}},{"cell_type":"code","source":"# Checking whether the dataset is balanced or not \ndisease_counts = data[\"prognosis\"].value_counts() \ntemp_df = pd.DataFrame({ \n    \"Disease\": disease_counts.index, \n    \"Counts\": disease_counts.values \n}) \n\nplt.figure(figsize = (18,8)) \nsns.barplot(x = \"Disease\", y = \"Counts\", data = temp_df) \nplt.xticks(rotation=90) \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T10:54:41.755436Z","iopub.execute_input":"2024-06-19T10:54:41.755835Z","iopub.status.idle":"2024-06-19T10:54:42.377189Z","shell.execute_reply.started":"2024-06-19T10:54:41.755805Z","shell.execute_reply":"2024-06-19T10:54:42.376192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above plot, we can observe that the dataset is a balanced dataset i.e. there are exactly 120 samples for each disease, and no further balancing is required. We can notice that our target column i.e. prognosis column is of object datatype, this format is not suitable to train a machine learning model. So, we will be using a label encoder to convert the prognosis column to the numerical datatype. Label Encoder converts the labels into numerical form by assigning a unique index to the labels. If the total number of labels is n, then the numbers assigned to each label will be between 0 to n-1.","metadata":{}},{"cell_type":"code","source":"# Encoding the target value into numerical \n# value using LabelEncoder \nencoder = LabelEncoder() \ndata[\"prognosis\"] = encoder.fit_transform(data[\"prognosis\"]) \n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T10:57:16.938099Z","iopub.execute_input":"2024-06-19T10:57:16.93856Z","iopub.status.idle":"2024-06-19T10:57:16.946209Z","shell.execute_reply.started":"2024-06-19T10:57:16.938525Z","shell.execute_reply":"2024-06-19T10:57:16.945111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Splitting the data for training and testing the model\nNow that we have cleaned our data by removing the Null values and converting the labels to numerical format, It’s time to split the data to train and test the model. We will be splitting the data into 80:20 format i.e. 80% of the dataset will be used for training the model and 20% of the data will be used to evaluate the performance of the models.","metadata":{}},{"cell_type":"code","source":"X = data.iloc[:,:-1] \ny = data.iloc[:, -1] \nX_train, X_test, y_train, y_test =train_test_split( \nX, y, test_size = 0.2, random_state = 24) \n\nprint(f\"Train: {X_train.shape}, {y_train.shape}\") \nprint(f\"Test: {X_test.shape}, {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-19T10:59:22.446572Z","iopub.execute_input":"2024-06-19T10:59:22.447275Z","iopub.status.idle":"2024-06-19T10:59:22.463088Z","shell.execute_reply.started":"2024-06-19T10:59:22.447243Z","shell.execute_reply":"2024-06-19T10:59:22.461764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model Building\nAfter splitting the data, we will be now working on the modeling part. We will be using K-Fold cross-validation to evaluate the machine-learning models. We will be using Support Vector Classifier, Gaussian Naive Bayes Classifier, and Random Forest Classifier for cross-validation. Before moving into the implementation part let us get familiar with k-fold cross-validation and the machine learning models. \n\nK-Fold Cross-Validation: K-Fold cross-validation is one of the cross-validation techniques in which the whole dataset is split into k number of subsets, also known as folds, then training of the model is performed on the k-1 subsets and the remaining one subset is used to evaluate the model performance.\n\nSupport Vector Classifier: Support Vector Classifier is a discriminative classifier i.e. when given a labeled training data, the algorithm tries to find an optimal hyperplane that accurately separates the samples into different categories in hyperspace.\n\nGaussian Naive Bayes Classifier: It is a probabilistic machine learning algorithm that internally uses Bayes Theorem to classify the data points.\n\nRandom Forest Classifier: Random Forest is an ensemble learning-based supervised machine learning classification algorithm that internally uses multiple decision trees to make the classification. In a random forest classifier, all the internal decision trees are weak learners, and the outputs of these weak decision trees are combined i.e. mode of all the predictions is as the final prediction.","metadata":{}},{"cell_type":"markdown","source":"Using K-Fold Cross-Validation for model selection ","metadata":{}},{"cell_type":"code","source":"# Defining scoring metric for k-fold cross validation \ndef cv_scoring(estimator, X, y): \n\treturn accuracy_score(y, estimator.predict(X)) \n\n# Initializing Models \nmodels = { \n\t\"SVC\":SVC(), \n\t\"Gaussian NB\":GaussianNB(), \n\t\"Random Forest\":RandomForestClassifier(random_state=18) \n} \n\n# Producing cross validation score for the models \nfor model_name in models: \n\tmodel = models[model_name] \n\tscores = cross_val_score(model, X, y, cv = 10, \n\t\t\t\t\t\t\tn_jobs = -1, \n\t\t\t\t\t\t\tscoring = cv_scoring) \n\tprint(\"==\"*30) \n\tprint(model_name) \n\tprint(f\"Scores: {scores}\") \n\tprint(f\"Mean Score: {np.mean(scores)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:00:29.939135Z","iopub.execute_input":"2024-06-19T11:00:29.93958Z","iopub.status.idle":"2024-06-19T11:00:36.184704Z","shell.execute_reply.started":"2024-06-19T11:00:29.939547Z","shell.execute_reply":"2024-06-19T11:00:36.183499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above output, we can notice that all our machine learning algorithms are performing very well and the mean scores after k fold cross-validation are also very high. To build a robust model we can combine i.e. take the mode of the predictions of all three models so that even one of the models makes wrong predictions and the other two make correct predictions then the final output would be the correct one. This approach will help us to keep the predictions much more accurate on completely unseen data. In the below code we will be training all the three models on the train data, checking the quality of our models using a confusion matrix, and then combine the predictions of all three models.","metadata":{}},{"cell_type":"markdown","source":"Building robust classifier by combining all models: ","metadata":{}},{"cell_type":"code","source":"# Training and testing SVM Classifier \nsvm_model = SVC() \nsvm_model.fit(X_train, y_train) \npreds = svm_model.predict(X_test) \n\nprint(f\"Accuracy on train data by SVM Classifier\\ : {accuracy_score(y_train, svm_model.predict(X_train))*100}\") \n\nprint(f\"Accuracy on test data by SVM Classifier\\ : {accuracy_score(y_test, preds)*100}\") \ncf_matrix = confusion_matrix(y_test, preds) \nplt.figure(figsize=(12,8)) \nsns.heatmap(cf_matrix, annot=True) \nplt.title(\"Confusion Matrix for SVM Classifier on Test Data\") \nplt.show() \n\n# Training and testing Naive Bayes Classifier \nnb_model = GaussianNB() \nnb_model.fit(X_train, y_train) \npreds = nb_model.predict(X_test) \nprint(f\"Accuracy on train data by Naive Bayes Classifier\\ : {accuracy_score(y_train, nb_model.predict(X_train))*100}\") \n\nprint(f\"Accuracy on test data by Naive Bayes Classifier\\ : {accuracy_score(y_test, preds)*100}\") \ncf_matrix = confusion_matrix(y_test, preds) \nplt.figure(figsize=(12,8)) \nsns.heatmap(cf_matrix, annot=True) \nplt.title(\"Confusion Matrix for Naive Bayes Classifier on Test Data\") \nplt.show() \n\n# Training and testing Random Forest Classifier \nrf_model = RandomForestClassifier(random_state=18) \nrf_model.fit(X_train, y_train) \npreds = rf_model.predict(X_test) \nprint(f\"Accuracy on train data by Random Forest Classifier\\ : {accuracy_score(y_train, rf_model.predict(X_train))*100}\") \n\nprint(f\"Accuracy on test data by Random Forest Classifier\\ : {accuracy_score(y_test, preds)*100}\") \n\ncf_matrix = confusion_matrix(y_test, preds) \nplt.figure(figsize=(12,8)) \nsns.heatmap(cf_matrix, annot=True) \nplt.title(\"Confusion Matrix for Random Forest Classifier on Test Data\") \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:02:52.486312Z","iopub.execute_input":"2024-06-19T11:02:52.487241Z","iopub.status.idle":"2024-06-19T11:03:04.959041Z","shell.execute_reply.started":"2024-06-19T11:02:52.487203Z","shell.execute_reply":"2024-06-19T11:03:04.95806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above confusion matrices, we can see that the models are performing very well on the unseen data. Now we will be training the models on the whole train data present in the dataset that we downloaded and then test our combined model on test data present in the dataset.","metadata":{}},{"cell_type":"markdown","source":"Fitting the model on whole data and validating on the Test dataset: ","metadata":{}},{"cell_type":"code","source":"from scipy.stats import mode\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:06:04.133929Z","iopub.execute_input":"2024-06-19T11:06:04.134315Z","iopub.status.idle":"2024-06-19T11:06:04.13936Z","shell.execute_reply.started":"2024-06-19T11:06:04.134286Z","shell.execute_reply":"2024-06-19T11:06:04.138084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the models on whole data\nfinal_svm_model = SVC()\nfinal_nb_model = GaussianNB()\nfinal_rf_model = RandomForestClassifier(random_state=18)\n\nfinal_svm_model.fit(X, y)\nfinal_nb_model.fit(X, y)\nfinal_rf_model.fit(X, y)\n\n# Reading the test data\ntest_data = pd.read_csv(\"/kaggle/input/disesase-dataset/d_testing.csv\").dropna(axis=1)\n\ntest_X = test_data.iloc[:, :-1]\ntest_Y = encoder.transform(test_data.iloc[:, -1])\n\n# Making predictions by taking the mode of predictions made by all the classifiers\nsvm_preds = final_svm_model.predict(test_X)\nnb_preds = final_nb_model.predict(test_X)\nrf_preds = final_rf_model.predict(test_X)\n\nfinal_preds = mode(np.array([svm_preds, nb_preds, rf_preds]))[0].flatten()\n\nprint(f\"Accuracy on Test dataset by the combined model: {accuracy_score(test_Y, final_preds) * 100:.2f}%\")\n\ncf_matrix = confusion_matrix(test_Y, final_preds)\nplt.figure(figsize=(12, 8))\nsns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix for Combined Model on Test Dataset\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:09:20.749453Z","iopub.execute_input":"2024-06-19T11:09:20.750104Z","iopub.status.idle":"2024-06-19T11:09:25.386456Z","shell.execute_reply.started":"2024-06-19T11:09:20.750072Z","shell.execute_reply":"2024-06-19T11:09:25.385448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that our combined model has classified all the data points accurately. We have come to the final part of this whole implementation, we will be creating a function that takes symptoms separated by commas as input and outputs the predicted disease using the combined model based on the input symptoms.","metadata":{}},{"cell_type":"markdown","source":"Creating a function that can take symptoms as input and generate predictions for disease ","metadata":{}},{"cell_type":"code","source":"# Checking the symptom columns\nsymptoms = X.columns.values \n\n# Creating a symptom index dictionary to encode the input symptoms into numerical form \nsymptom_index = {} \nfor index, value in enumerate(symptoms): \n    symptom = \" \".join([i.capitalize() for i in value.split(\"_\")]) \n    symptom_index[symptom] = index \n\ndata_dict = { \n    \"symptom_index\":symptom_index, \n    \"predictions_classes\":encoder.classes_ \n} \n\n# Defining the Function \n# Input: string containing symptoms separated by commas \n# Output: Generated predictions by models as a DataFrame\ndef predictDisease(symptoms): \n    symptoms = symptoms.split(\",\") \n    \n    # creating input data for the models \n    input_data = [0] * len(data_dict[\"symptom_index\"]) \n    for symptom in symptoms: \n        index = data_dict[\"symptom_index\"][symptom] \n        input_data[index] = 1\n\n    # reshaping the input data and converting it into suitable format for model predictions \n    input_data = pd.DataFrame([input_data], columns=X.columns)\n\n    # generating individual outputs \n    rf_prediction = data_dict[\"predictions_classes\"][final_rf_model.predict(input_data)[0]] \n    nb_prediction = data_dict[\"predictions_classes\"][final_nb_model.predict(input_data)[0]] \n    svm_prediction = data_dict[\"predictions_classes\"][final_svm_model.predict(input_data)[0]] \n\n    # making final prediction by taking mode of all predictions \n    final_prediction = Counter([rf_prediction, nb_prediction, svm_prediction]).most_common(1)[0][0]\n    \n    # Create a DataFrame with predictions\n    predictions_df = pd.DataFrame({\n        \"rf_model_prediction\": [rf_prediction],\n        \"naive_bayes_prediction\": [nb_prediction],\n        \"svm_model_prediction\": [svm_prediction],\n        \"FINAL PREDICTION\": [final_prediction]\n    })\n    \n    return predictions_df\n\n# Testing the function \npredictDisease(\"Itching,Skin Rash,Nodal Skin Eruptions\")","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:22:40.725967Z","iopub.execute_input":"2024-06-19T11:22:40.726787Z","iopub.status.idle":"2024-06-19T11:22:40.765125Z","shell.execute_reply.started":"2024-06-19T11:22:40.72675Z","shell.execute_reply":"2024-06-19T11:22:40.764039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictDisease(\"Shivering,Chills,Vomiting,Fatigue\")","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:25:33.438728Z","iopub.execute_input":"2024-06-19T11:25:33.43922Z","iopub.status.idle":"2024-06-19T11:25:33.470131Z","shell.execute_reply.started":"2024-06-19T11:25:33.43918Z","shell.execute_reply":"2024-06-19T11:25:33.469109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictDisease(\"Runny Nose,Chest Pain,Dizziness\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-19T11:28:03.4845Z","iopub.execute_input":"2024-06-19T11:28:03.485166Z","iopub.status.idle":"2024-06-19T11:28:03.515714Z","shell.execute_reply.started":"2024-06-19T11:28:03.485135Z","shell.execute_reply":"2024-06-19T11:28:03.514691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note: The symptoms that are given as input to the function should be exactly the same among the 132 symptoms in the dataset.","metadata":{}}]}